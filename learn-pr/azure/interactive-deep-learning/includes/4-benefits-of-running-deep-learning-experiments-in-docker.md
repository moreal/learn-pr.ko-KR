![Docker 로고](../media/3-image1.PNG)

<span data-ttu-id="99312-102">Docker는 선택한 호스트 운영 체제에서 실행되도록 샌드박스에 응용 프로그램을 배포할 수 있는 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="99312-102">Docker is a tool that allows you to deploy your applications in a sandbox to run on a host operating system of your choice.</span></span> <span data-ttu-id="99312-103">표준화된 단위로 모든 종속성과 함께 앱을 패키지화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="99312-103">It allows you to package your app with all of its dependencies in a standardized unit.</span></span> <span data-ttu-id="99312-104">그러나 DSVM 기본 이미지가 이미 설치된 가장 인기 있는 딥 러닝 프레임워크와 함께 제공되는 경우 Docker를 사용할 이유가 있을까요?</span><span class="sxs-lookup"><span data-stu-id="99312-104">But if the DSVM base image comes with the most popular deep learning frameworks already pre-installed, why would you use Docker?</span></span>

<span data-ttu-id="99312-105">딥 러닝 작업을 실행하려고 하는 경우 개발자는 종속성 문제에 직면하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="99312-105">When attempting to run deep learning tasks, developers find themselves facing dependency issues.</span></span> <span data-ttu-id="99312-106">예:</span><span class="sxs-lookup"><span data-stu-id="99312-106">For example:</span></span> 

- <span data-ttu-id="99312-107">사용자 지정 패키지를 빌드해야 함 - 딥 러닝 연구원들은 GitHub에 코드를 게시할 때 프로덕션 환경에 대해서는 크게 고려하지 않는 경향이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="99312-107">Having to build custom packages - Deep learning researchers tend to think less about production when they publish code to GitHub.</span></span> <span data-ttu-id="99312-108">즉, 연구원의 개발 환경에서 패키지가 작동하면 다른 사용자도 패키지를 실행할 수 있다고 가정하는 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="99312-108">If they can get a package working on their own development environment, they often just assume that others will be able to do so as well.</span></span>
- <span data-ttu-id="99312-109">GPU 드라이버 버전 관리 - CUDA는 NVIDIA에서 개발한 병렬 컴퓨팅 플랫폼이자 API(응용 프로그래밍 인터페이스)입니다.</span><span class="sxs-lookup"><span data-stu-id="99312-109">GPU driver versioning - CUDA is a parallel computing platform and application programming interface (API) developed by NVIDIA.</span></span> <span data-ttu-id="99312-110">CUDA를 사용하는 개발자는 CUDA 지원 GPU(그래픽 처리 장치)를 범용 처리에 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="99312-110">It allows developers to use a CUDA-enabled graphics processing unit (GPU) for general-purpose processing.</span></span> <span data-ttu-id="99312-111">Tensorflow의 특정 버전은 CUDA 9.1 이상 버전에서 작동하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="99312-111">Certain versions of Tensorflow will not work with versions of CUDA above 9.1.</span></span> <span data-ttu-id="99312-112">PyTorch 등 다른 프레임워크는 CUDA의 이후 버전에서 더 원활히 수행됩니다.</span><span class="sxs-lookup"><span data-stu-id="99312-112">Other frameworks, such as PyTorch, seem to perform better with later versions of CUDA.</span></span>

<span data-ttu-id="99312-113">이러한 문제를 해결하고 코드의 유용성을 개선하려는 경우 Docker 또는 Docker의 GPU 변형인 NVIDIA Docker를 사용하여 딥 러닝 프로젝트를 관리하고 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="99312-113">To get around these issues and to increase the usability of code, you can use Docker or its GPU variant NVIDIA Docker to manage and run deep learning projects.</span></span> 

<!--Quiz 
What is CUDA? 
What versioning issues do deep learning engineers deal with? -->